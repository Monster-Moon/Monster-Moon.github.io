---
layout: post
title:  "Learning a HLSM via l_1-Regularized Regression."
date:   2021-06-01 12:00:00 +0100
categories:
---

## Learning a HLSM via l_1-Regularized Regression

이 연구는 Bayesian network에서 일반적으로 가정하는 faithfulness, Gaussian error distribution, equal error distribution conditions 없이 고차원 선형 구조 방정식 모델 (SEM)을 학습하는 새로운 접근 방식을 개발한다. 

알고리즘의 핵심 구성 요소는 component-wise한 ordering 추정과 및 parent 추정이며, 두 문제 모두 l1-정규화 된 회귀 모형를 사용하여 효율적으로 해결할 수 있다.

제안 알고리즘이 sub-Gaussian, (4m)-th bounded error distribution에 대한 선형 SEMs을 recover하는데 각각 Omega(d^2 log p), Omega(d^2 p^{2/m})의 표본이면 충분함을 보였다. 이 때, d는 moralized graph의 maximum degree, p는 노드의 개수를 의미한다.

최악의 경우 계산 복잡성 O(n(p^3+p^2d^2))을 가지므로 제안 알고리즘은 moralized graph가 sparse할 때 통계적으로 consistent하고 계산 가능한 고차원 선형 SEM을 학습 할 수 있다.

논문 게재에 성공했다! <a href='http://jmlr.org/papers/v22/20-1005.html'>[link]</a>